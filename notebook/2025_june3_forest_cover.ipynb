{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3994ca24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    " \n",
    "df = pd.read_csv('/Users/mustakahmad/Library/CloudStorage/OneDrive-purdue.edu/FACAI LAB/Project3_tariff/tariff_war/raw_data/soybean/Brazil_Forest_Loss_2013_2022_1km.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e4515f15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>system:index</th>\n",
       "      <th>gain</th>\n",
       "      <th>loss</th>\n",
       "      <th>loss_year</th>\n",
       "      <th>treecover2000</th>\n",
       "      <th>.geo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2019</td>\n",
       "      <td>100</td>\n",
       "      <td>{\"geodesic\":false,\"type\":\"Point\",\"coordinates\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2019</td>\n",
       "      <td>100</td>\n",
       "      <td>{\"geodesic\":false,\"type\":\"Point\",\"coordinates\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2019</td>\n",
       "      <td>100</td>\n",
       "      <td>{\"geodesic\":false,\"type\":\"Point\",\"coordinates\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2019</td>\n",
       "      <td>100</td>\n",
       "      <td>{\"geodesic\":false,\"type\":\"Point\",\"coordinates\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2019</td>\n",
       "      <td>100</td>\n",
       "      <td>{\"geodesic\":false,\"type\":\"Point\",\"coordinates\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2062992</th>\n",
       "      <td>2062992</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2022</td>\n",
       "      <td>6</td>\n",
       "      <td>{\"geodesic\":false,\"type\":\"Point\",\"coordinates\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2062993</th>\n",
       "      <td>2062993</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020</td>\n",
       "      <td>2</td>\n",
       "      <td>{\"geodesic\":false,\"type\":\"Point\",\"coordinates\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2062994</th>\n",
       "      <td>2062994</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>{\"geodesic\":false,\"type\":\"Point\",\"coordinates\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2062995</th>\n",
       "      <td>2062995</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2018</td>\n",
       "      <td>4</td>\n",
       "      <td>{\"geodesic\":false,\"type\":\"Point\",\"coordinates\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2062996</th>\n",
       "      <td>2062996</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>{\"geodesic\":false,\"type\":\"Point\",\"coordinates\"...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2062997 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         system:index  gain  loss  loss_year  treecover2000  \\\n",
       "0                   0     0     0       2019            100   \n",
       "1                   1     0     1       2019            100   \n",
       "2                   2     0     0       2019            100   \n",
       "3                   3     0     0       2019            100   \n",
       "4                   4     0     0       2019            100   \n",
       "...               ...   ...   ...        ...            ...   \n",
       "2062992       2062992     0     0       2022              6   \n",
       "2062993       2062993     0     0       2020              2   \n",
       "2062994       2062994     0     0       2017              1   \n",
       "2062995       2062995     0     0       2018              4   \n",
       "2062996       2062996     0     0       2016              1   \n",
       "\n",
       "                                                      .geo  \n",
       "0        {\"geodesic\":false,\"type\":\"Point\",\"coordinates\"...  \n",
       "1        {\"geodesic\":false,\"type\":\"Point\",\"coordinates\"...  \n",
       "2        {\"geodesic\":false,\"type\":\"Point\",\"coordinates\"...  \n",
       "3        {\"geodesic\":false,\"type\":\"Point\",\"coordinates\"...  \n",
       "4        {\"geodesic\":false,\"type\":\"Point\",\"coordinates\"...  \n",
       "...                                                    ...  \n",
       "2062992  {\"geodesic\":false,\"type\":\"Point\",\"coordinates\"...  \n",
       "2062993  {\"geodesic\":false,\"type\":\"Point\",\"coordinates\"...  \n",
       "2062994  {\"geodesic\":false,\"type\":\"Point\",\"coordinates\"...  \n",
       "2062995  {\"geodesic\":false,\"type\":\"Point\",\"coordinates\"...  \n",
       "2062996  {\"geodesic\":false,\"type\":\"Point\",\"coordinates\"...  \n",
       "\n",
       "[2062997 rows x 6 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "46c43224",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mustakahmad/Library/CloudStorage/OneDrive-purdue.edu/FACAI LAB/Project3_tariff/proj3env/lib/python3.12/site-packages/ee/deprecation.py:207: DeprecationWarning: \n",
      "\n",
      "Attention required for UMD/hansen/global_forest_change_2022_v1_10! You are using a deprecated asset.\n",
      "To make sure your code keeps working, please update it.\n",
      "Learn more: https://developers.google.com/earth-engine/datasets/catalog/UMD_hansen_global_forest_change_2022_v1_10\n",
      "\n",
      "  warnings.warn(warning, category=DeprecationWarning)\n"
     ]
    },
    {
     "ename": "EEException",
     "evalue": "Collection query aborted after accumulating over 5000 elements.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mHttpError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/CloudStorage/OneDrive-purdue.edu/FACAI LAB/Project3_tariff/proj3env/lib/python3.12/site-packages/ee/data.py:408\u001b[39m, in \u001b[36m_execute_cloud_call\u001b[39m\u001b[34m(call, num_retries)\u001b[39m\n\u001b[32m    407\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m408\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_retries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_retries\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    409\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m googleapiclient.errors.HttpError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/CloudStorage/OneDrive-purdue.edu/FACAI LAB/Project3_tariff/proj3env/lib/python3.12/site-packages/googleapiclient/_helpers.py:130\u001b[39m, in \u001b[36mpositional.<locals>.positional_decorator.<locals>.positional_wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    129\u001b[39m         logger.warning(message)\n\u001b[32m--> \u001b[39m\u001b[32m130\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/CloudStorage/OneDrive-purdue.edu/FACAI LAB/Project3_tariff/proj3env/lib/python3.12/site-packages/googleapiclient/http.py:938\u001b[39m, in \u001b[36mHttpRequest.execute\u001b[39m\u001b[34m(self, http, num_retries)\u001b[39m\n\u001b[32m    937\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m resp.status >= \u001b[32m300\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m938\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m HttpError(resp, content, uri=\u001b[38;5;28mself\u001b[39m.uri)\n\u001b[32m    939\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.postproc(resp, content)\n",
      "\u001b[31mHttpError\u001b[39m: <HttpError 400 when requesting https://earthengine.googleapis.com/v1/projects/forest-cover-461900/value:compute?prettyPrint=false&alt=json returned \"Collection query aborted after accumulating over 5000 elements.\". Details: \"Collection query aborted after accumulating over 5000 elements.\">",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mEEException\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 61\u001b[39m\n\u001b[32m     58\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m pd.DataFrame(data)\n\u001b[32m     60\u001b[39m \u001b[38;5;66;03m# WARNING: May timeout if too many points; sample small region for testing\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m61\u001b[39m df = \u001b[43mee_to_df\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     63\u001b[39m \u001b[38;5;66;03m# Save to CSV\u001b[39;00m\n\u001b[32m     64\u001b[39m df.to_csv(\u001b[33m'\u001b[39m\u001b[33mbrazil_forest_loss_ha_2015_2022.csv\u001b[39m\u001b[33m'\u001b[39m, index=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 50\u001b[39m, in \u001b[36mee_to_df\u001b[39m\u001b[34m(feature_coll)\u001b[39m\n\u001b[32m     48\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mee_to_df\u001b[39m(feature_coll):\n\u001b[32m     49\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Convert FeatureCollection to Pandas DataFrame\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m50\u001b[39m     features = \u001b[43mfeature_coll\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetInfo\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[\u001b[33m'\u001b[39m\u001b[33mfeatures\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     51\u001b[39m     data = []\n\u001b[32m     52\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m features:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/CloudStorage/OneDrive-purdue.edu/FACAI LAB/Project3_tariff/proj3env/lib/python3.12/site-packages/ee/collection.py:579\u001b[39m, in \u001b[36mCollection.getInfo\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    566\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgetInfo\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> Optional[Any]:\n\u001b[32m    567\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Returns all the known information about this collection.\u001b[39;00m\n\u001b[32m    568\u001b[39m \n\u001b[32m    569\u001b[39m \u001b[33;03m  This function makes a REST call to to retrieve all the known information\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    577\u001b[39m \u001b[33;03m         properties.\u001b[39;00m\n\u001b[32m    578\u001b[39m \u001b[33;03m  \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m579\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetInfo\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/CloudStorage/OneDrive-purdue.edu/FACAI LAB/Project3_tariff/proj3env/lib/python3.12/site-packages/ee/computedobject.py:107\u001b[39m, in \u001b[36mComputedObject.getInfo\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    101\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgetInfo\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> Optional[Any]:\n\u001b[32m    102\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Fetch and return information about this object.\u001b[39;00m\n\u001b[32m    103\u001b[39m \n\u001b[32m    104\u001b[39m \u001b[33;03m  Returns:\u001b[39;00m\n\u001b[32m    105\u001b[39m \u001b[33;03m    The object can evaluate to anything.\u001b[39;00m\n\u001b[32m    106\u001b[39m \u001b[33;03m  \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m107\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcomputeValue\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/CloudStorage/OneDrive-purdue.edu/FACAI LAB/Project3_tariff/proj3env/lib/python3.12/site-packages/ee/data.py:1128\u001b[39m, in \u001b[36mcomputeValue\u001b[39m\u001b[34m(obj)\u001b[39m\n\u001b[32m   1125\u001b[39m body = {\u001b[33m'\u001b[39m\u001b[33mexpression\u001b[39m\u001b[33m'\u001b[39m: serializer.encode(obj, for_cloud_api=\u001b[38;5;28;01mTrue\u001b[39;00m)}\n\u001b[32m   1126\u001b[39m _maybe_populate_workload_tag(body)\n\u001b[32m-> \u001b[39m\u001b[32m1128\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_execute_cloud_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1129\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_get_cloud_projects\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1130\u001b[39m \u001b[43m    \u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1131\u001b[39m \u001b[43m    \u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproject\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_get_projects_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprettyPrint\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   1132\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m[\u001b[33m'\u001b[39m\u001b[33mresult\u001b[39m\u001b[33m'\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/CloudStorage/OneDrive-purdue.edu/FACAI LAB/Project3_tariff/proj3env/lib/python3.12/site-packages/ee/data.py:410\u001b[39m, in \u001b[36m_execute_cloud_call\u001b[39m\u001b[34m(call, num_retries)\u001b[39m\n\u001b[32m    408\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m call.execute(num_retries=num_retries)\n\u001b[32m    409\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m googleapiclient.errors.HttpError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m410\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m _translate_cloud_exception(e)\n",
      "\u001b[31mEEException\u001b[39m: Collection query aborted after accumulating over 5000 elements."
     ]
    }
   ],
   "source": [
    "import ee\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize Earth Engine\n",
    "ee.Initialize(project= 'forest-cover-461900')\n",
    "\n",
    "# Load Brazil boundary\n",
    "brazil = ee.FeatureCollection(\"FAO/GAUL/2015/level0\") \\\n",
    "           .filter(ee.Filter.eq('ADM0_NAME', 'Brazil'))\n",
    "\n",
    "# Load Hansen dataset\n",
    "hansen = ee.Image('UMD/hansen/global_forest_change_2022_v1_10')\n",
    "lossyear = hansen.select('lossyear')\n",
    "treecover = hansen.select('treecover2000')\n",
    "\n",
    "# Forest mask and loss year image (masked to forest)\n",
    "forest_mask = treecover.gt(0)\n",
    "loss_masked = lossyear.updateMask(forest_mask)\n",
    "\n",
    "# Pixel area in hectares\n",
    "pixel_area_ha = ee.Image.pixelArea().divide(10000)\n",
    "loss_area_ha = pixel_area_ha.updateMask(loss_masked)\n",
    "\n",
    "# Add actual year band (2000 + lossyear)\n",
    "year_band = loss_masked.add(2000).rename('Year')\n",
    "loss_ha_band = loss_area_ha.rename('LossHa')\n",
    "\n",
    "# Combine bands\n",
    "loss_image = year_band.addBands(loss_ha_band)\n",
    "\n",
    "# Reproject to 1km for manageable size\n",
    "loss_image = loss_image.reproject(crs='EPSG:4326', scale=1000)\n",
    "\n",
    "# Sample the image\n",
    "samples = loss_image.sample(\n",
    "    region=brazil.geometry(),\n",
    "    scale=1000,\n",
    "    geometries=True,\n",
    "    numPixels=1e6,  # cap at 1M pixels to avoid memory issue\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "# Filter to 2015–2022\n",
    "samples = samples.filter(ee.Filter.gte('Year', 2015)) \\\n",
    "                 .filter(ee.Filter.lte('Year', 2022))\n",
    "\n",
    "# Get results to client (only works for small exports)\n",
    "def ee_to_df(feature_coll):\n",
    "    \"\"\"Convert FeatureCollection to Pandas DataFrame\"\"\"\n",
    "    features = feature_coll.getInfo()['features']\n",
    "    data = []\n",
    "    for f in features:\n",
    "        props = f['properties']\n",
    "        coords = f['geometry']['coordinates']\n",
    "        props['Longitude'] = coords[0]\n",
    "        props['Latitude'] = coords[1]\n",
    "        data.append(props)\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# WARNING: May timeout if too many points; sample small region for testing\n",
    "df = ee_to_df(samples)\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv('brazil_forest_loss_ha_2015_2022.csv', index=False)\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a8f6a626",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Export started. Check the GEE Code Editor 'Tasks' tab or Google Drive.\n"
     ]
    }
   ],
   "source": [
    "import ee\n",
    "ee.Initialize(project= 'forest-cover-461900')\n",
    "\n",
    "# 1. Define Brazil boundary\n",
    "brazil = ee.FeatureCollection(\"FAO/GAUL/2015/level0\") \\\n",
    "           .filter(ee.Filter.eq('ADM0_NAME', 'Brazil'))\n",
    "\n",
    "# 2. Load Hansen forest change dataset\n",
    "hansen = ee.Image('UMD/hansen/global_forest_change_2022_v1_10')\n",
    "\n",
    "# 3. Select relevant bands\n",
    "treecover2000 = hansen.select('treecover2000')\n",
    "loss = hansen.select('loss')\n",
    "lossyear = hansen.select('lossyear')\n",
    "gain = hansen.select('gain')\n",
    "\n",
    "# 4. Mask forest loss from 2015 to 2022\n",
    "loss_mask = lossyear.gte(15).And(lossyear.lte(22))\n",
    "loss_filtered = lossyear.updateMask(loss_mask)\n",
    "\n",
    "# 5. Convert loss year to actual year (2000 + value)\n",
    "loss_year_actual = loss_filtered.add(2000).rename('loss_year')\n",
    "\n",
    "# 6. Stack all required bands\n",
    "stack = treecover2000.addBands(loss).addBands(gain).addBands(loss_year_actual)\n",
    "\n",
    "# 7. Clip to Brazil and reproject\n",
    "stack_clipped = stack.clip(brazil).reproject(crs='EPSG:4326', scale=1000)\n",
    "\n",
    "# 8. Sample pixels\n",
    "samples = stack_clipped.sample(\n",
    "    region=brazil.geometry(),\n",
    "    scale=1000,\n",
    "    geometries=True\n",
    ")\n",
    "\n",
    "# 9. Export to Google Drive as CSV\n",
    "task = ee.batch.Export.table.toDrive(\n",
    "    collection=samples,\n",
    "    description='Brazil_Forest_Loss_2015_2022',\n",
    "    fileFormat='CSV'\n",
    ")\n",
    "\n",
    "task.start()\n",
    "print(\"Export started. Check the GEE Code Editor 'Tasks' tab or Google Drive.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "proj3env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
